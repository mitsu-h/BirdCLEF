{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitsu-h/BirdCLEF/blob/oversampling/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f66c33fa",
      "metadata": {
        "papermill": {
          "duration": 0.052292,
          "end_time": "2022-03-24T06:01:48.721975",
          "exception": false,
          "start_time": "2022-03-24T06:01:48.669683",
          "status": "completed"
        },
        "tags": [],
        "id": "f66c33fa"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d0cdc40",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:48.839653Z",
          "iopub.status.busy": "2022-03-24T06:01:48.838798Z",
          "iopub.status.idle": "2022-03-24T06:01:52.215133Z",
          "shell.execute_reply": "2022-03-24T06:01:52.214312Z",
          "shell.execute_reply.started": "2022-03-24T05:58:34.133375Z"
        },
        "papermill": {
          "duration": 3.440413,
          "end_time": "2022-03-24T06:01:52.215334",
          "exception": false,
          "start_time": "2022-03-24T06:01:48.774921",
          "status": "completed"
        },
        "tags": [],
        "id": "3d0cdc40"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install audiomentations"
      ],
      "metadata": {
        "id": "li3Zv3SAWCRi"
      },
      "id": "li3Zv3SAWCRi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf08e367",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:52.386927Z",
          "iopub.status.busy": "2022-03-24T06:01:52.386146Z",
          "iopub.status.idle": "2022-03-24T06:01:54.792502Z",
          "shell.execute_reply": "2022-03-24T06:01:54.793261Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.159113Z"
        },
        "papermill": {
          "duration": 2.494431,
          "end_time": "2022-03-24T06:01:54.793470",
          "exception": false,
          "start_time": "2022-03-24T06:01:52.299039",
          "status": "completed"
        },
        "tags": [],
        "id": "bf08e367"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import soundfile as sf\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
        "\n",
        "import torchaudio\n",
        "from torchaudio import transforms\n",
        "import torchvision\n",
        "from audiomentations import Compose, AddGaussianNoise, PitchShift, TimeStretch, Shift\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "metadata": {
        "id": "Er6bliRJvX3n"
      },
      "id": "Er6bliRJvX3n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "aTCCqvhUvaSv"
      },
      "id": "aTCCqvhUvaSv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_fix_seed(seed=42):\n",
        "    # Python random\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.use_deterministic_algorithms = True\n",
        "\n",
        "\n",
        "torch_fix_seed()"
      ],
      "metadata": {
        "id": "tvHifIWc2zD-"
      },
      "execution_count": null,
      "outputs": [],
      "id": "tvHifIWc2zD-"
    },
    {
      "cell_type": "markdown",
      "id": "9c7b8a33",
      "metadata": {
        "papermill": {
          "duration": 0.072465,
          "end_time": "2022-03-24T06:01:54.937721",
          "exception": false,
          "start_time": "2022-03-24T06:01:54.865256",
          "status": "completed"
        },
        "tags": [],
        "id": "9c7b8a33"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_dir=\"/content/drive/MyDrive/colab/BirdCLEF/\"\n",
        "data_dir= os.path.join(root_dir, \"inputs/\")\n",
        "model_dir = os.path.join(root_dir, \"models/\")"
      ],
      "metadata": {
        "id": "0OCleE3RXUQF"
      },
      "id": "0OCleE3RXUQF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10cdb6df",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:55.084919Z",
          "iopub.status.busy": "2022-03-24T06:01:55.084336Z",
          "iopub.status.idle": "2022-03-24T06:01:55.197264Z",
          "shell.execute_reply": "2022-03-24T06:01:55.197704Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.166571Z"
        },
        "papermill": {
          "duration": 0.189177,
          "end_time": "2022-03-24T06:01:55.197851",
          "exception": false,
          "start_time": "2022-03-24T06:01:55.008674",
          "status": "completed"
        },
        "tags": [],
        "id": "10cdb6df"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(os.path.join(data_dir, 'train_metadata.csv'))\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef2675f1",
      "metadata": {
        "papermill": {
          "duration": 0.072072,
          "end_time": "2022-03-24T06:01:55.342024",
          "exception": false,
          "start_time": "2022-03-24T06:01:55.269952",
          "status": "completed"
        },
        "tags": [],
        "id": "ef2675f1"
      },
      "source": [
        "# Quick EDA and Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a9dba2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:55.490530Z",
          "iopub.status.busy": "2022-03-24T06:01:55.489908Z",
          "iopub.status.idle": "2022-03-24T06:01:55.492563Z",
          "shell.execute_reply": "2022-03-24T06:01:55.492957Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.243753Z"
        },
        "papermill": {
          "duration": 0.079321,
          "end_time": "2022-03-24T06:01:55.493085",
          "exception": false,
          "start_time": "2022-03-24T06:01:55.413764",
          "status": "completed"
        },
        "tags": [],
        "id": "17a9dba2"
      },
      "outputs": [],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0be079a6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:55.650190Z",
          "iopub.status.busy": "2022-03-24T06:01:55.649356Z",
          "iopub.status.idle": "2022-03-24T06:01:55.668035Z",
          "shell.execute_reply": "2022-03-24T06:01:55.668539Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.251810Z"
        },
        "papermill": {
          "duration": 0.104483,
          "end_time": "2022-03-24T06:01:55.668690",
          "exception": false,
          "start_time": "2022-03-24T06:01:55.564207",
          "status": "completed"
        },
        "tags": [],
        "id": "0be079a6"
      },
      "outputs": [],
      "source": [
        "train_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e351bbf2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:55.835179Z",
          "iopub.status.busy": "2022-03-24T06:01:55.834235Z",
          "iopub.status.idle": "2022-03-24T06:01:55.864584Z",
          "shell.execute_reply": "2022-03-24T06:01:55.863964Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.277404Z"
        },
        "papermill": {
          "duration": 0.1112,
          "end_time": "2022-03-24T06:01:55.864742",
          "exception": false,
          "start_time": "2022-03-24T06:01:55.753542",
          "status": "completed"
        },
        "tags": [],
        "id": "e351bbf2"
      },
      "outputs": [],
      "source": [
        "train_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66b8d58c",
      "metadata": {
        "papermill": {
          "duration": 0.077177,
          "end_time": "2022-03-24T06:01:56.021174",
          "exception": false,
          "start_time": "2022-03-24T06:01:55.943997",
          "status": "completed"
        },
        "tags": [],
        "id": "66b8d58c"
      },
      "source": [
        "Looks like no null values are there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35f80ace",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:56.191272Z",
          "iopub.status.busy": "2022-03-24T06:01:56.190312Z",
          "iopub.status.idle": "2022-03-24T06:01:56.194250Z",
          "shell.execute_reply": "2022-03-24T06:01:56.194669Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.306456Z"
        },
        "papermill": {
          "duration": 0.096079,
          "end_time": "2022-03-24T06:01:56.194810",
          "exception": false,
          "start_time": "2022-03-24T06:01:56.098731",
          "status": "completed"
        },
        "tags": [],
        "id": "35f80ace"
      },
      "outputs": [],
      "source": [
        "# For this baseline notebook, we would consider following columns \n",
        "columns_of_interest = ['primary_label', 'secondary_labels', 'rating', 'filename']\n",
        "train_df = train_df[columns_of_interest]\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c02ae357",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:56.368959Z",
          "iopub.status.busy": "2022-03-24T06:01:56.368253Z",
          "iopub.status.idle": "2022-03-24T06:01:56.639606Z",
          "shell.execute_reply": "2022-03-24T06:01:56.639159Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.320563Z"
        },
        "papermill": {
          "duration": 0.357913,
          "end_time": "2022-03-24T06:01:56.639736",
          "exception": false,
          "start_time": "2022-03-24T06:01:56.281823",
          "status": "completed"
        },
        "tags": [],
        "id": "c02ae357"
      },
      "outputs": [],
      "source": [
        "f, ax = plt.subplots(figsize=(20,8))\n",
        "sns.countplot(x='rating', data=train_df, ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c98c4d27",
      "metadata": {
        "papermill": {
          "duration": 0.073494,
          "end_time": "2022-03-24T06:01:56.787896",
          "exception": false,
          "start_time": "2022-03-24T06:01:56.714402",
          "status": "completed"
        },
        "tags": [],
        "id": "c98c4d27"
      },
      "source": [
        "we will consider only those audio files whose rating >= 3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4426f985",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:56.941904Z",
          "iopub.status.busy": "2022-03-24T06:01:56.941149Z",
          "iopub.status.idle": "2022-03-24T06:01:56.944421Z",
          "shell.execute_reply": "2022-03-24T06:01:56.944030Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.576664Z"
        },
        "papermill": {
          "duration": 0.082325,
          "end_time": "2022-03-24T06:01:56.944561",
          "exception": false,
          "start_time": "2022-03-24T06:01:56.862236",
          "status": "completed"
        },
        "tags": [],
        "id": "4426f985"
      },
      "outputs": [],
      "source": [
        "train_df = train_df[train_df.rating >= 3.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "primary_labelのクラス比\n"
      ],
      "metadata": {
        "id": "pd65LNxiYkWJ"
      },
      "id": "pd65LNxiYkWJ"
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize=(30,8))\n",
        "sns.countplot(x=\"primary_label\", data=train_df, ax=ax)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cXUkh8QoWHT5"
      },
      "id": "cXUkh8QoWHT5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "secondary_labelsのクラス比"
      ],
      "metadata": {
        "id": "4Mx75jwOYuio"
      },
      "id": "4Mx75jwOYuio"
    },
    {
      "cell_type": "code",
      "source": [
        "secondary_labels = sum(train_df[\"secondary_labels\"].apply(lambda x: eval(x)).values, [])\n",
        "len(set(secondary_labels))"
      ],
      "metadata": {
        "id": "4IxlygywWQbR"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4IxlygywWQbR"
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize=(30,8))\n",
        "sns.countplot(x=sorted(secondary_labels), ax=ax)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZE7r54X-ZheB"
      },
      "execution_count": null,
      "outputs": [],
      "id": "ZE7r54X-ZheB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データが不均衡なため、データ数の逆数を重みとして利用"
      ],
      "metadata": {
        "id": "COM2s_Nv1wyP"
      },
      "id": "COM2s_Nv1wyP"
    },
    {
      "cell_type": "code",
      "source": [
        "label_weights = 1. / train_df.groupby(\"primary_label\").count()[\"filename\"]\n",
        "label_weights"
      ],
      "metadata": {
        "id": "FRf17Mw_ZpCq"
      },
      "id": "FRf17Mw_ZpCq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.groupby(\"primary_label\").count().describe()"
      ],
      "metadata": {
        "id": "2aKCwXGuRvE5"
      },
      "id": "2aKCwXGuRvE5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52a4fb3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:57.104915Z",
          "iopub.status.busy": "2022-03-24T06:01:57.104252Z",
          "iopub.status.idle": "2022-03-24T06:01:57.107155Z",
          "shell.execute_reply": "2022-03-24T06:01:57.107573Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.586679Z"
        },
        "papermill": {
          "duration": 0.08958,
          "end_time": "2022-03-24T06:01:57.107710",
          "exception": false,
          "start_time": "2022-03-24T06:01:57.018130",
          "status": "completed"
        },
        "tags": [],
        "id": "c52a4fb3"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.reset_index(drop=True)\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### label情報の作成"
      ],
      "metadata": {
        "id": "vPz-SmyMZDAy"
      },
      "id": "vPz-SmyMZDAy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e78526",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:57.261890Z",
          "iopub.status.busy": "2022-03-24T06:01:57.261343Z",
          "iopub.status.idle": "2022-03-24T06:01:57.265232Z",
          "shell.execute_reply": "2022-03-24T06:01:57.265677Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.600215Z"
        },
        "papermill": {
          "duration": 0.083002,
          "end_time": "2022-03-24T06:01:57.265806",
          "exception": false,
          "start_time": "2022-03-24T06:01:57.182804",
          "status": "completed"
        },
        "tags": [],
        "id": "21e78526"
      },
      "outputs": [],
      "source": [
        "labels = train_df.primary_label.unique().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b2e1a2f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:57.464054Z",
          "iopub.status.busy": "2022-03-24T06:01:57.463279Z",
          "iopub.status.idle": "2022-03-24T06:01:57.465727Z",
          "shell.execute_reply": "2022-03-24T06:01:57.465262Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.607164Z"
        },
        "papermill": {
          "duration": 0.125958,
          "end_time": "2022-03-24T06:01:57.465838",
          "exception": false,
          "start_time": "2022-03-24T06:01:57.339880",
          "status": "completed"
        },
        "tags": [],
        "id": "6b2e1a2f"
      },
      "outputs": [],
      "source": [
        "label2id = {labels[i]: i for i in range(len(labels))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af60ec5d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:57.618877Z",
          "iopub.status.busy": "2022-03-24T06:01:57.618234Z",
          "iopub.status.idle": "2022-03-24T06:01:57.620871Z",
          "shell.execute_reply": "2022-03-24T06:01:57.621261Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.615869Z"
        },
        "papermill": {
          "duration": 0.081681,
          "end_time": "2022-03-24T06:01:57.621388",
          "exception": false,
          "start_time": "2022-03-24T06:01:57.539707",
          "status": "completed"
        },
        "tags": [],
        "id": "af60ec5d"
      },
      "outputs": [],
      "source": [
        "labels[0], label2id['afrsil1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07bee216",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:57.774040Z",
          "iopub.status.busy": "2022-03-24T06:01:57.773324Z",
          "iopub.status.idle": "2022-03-24T06:01:57.776046Z",
          "shell.execute_reply": "2022-03-24T06:01:57.776410Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.628189Z"
        },
        "papermill": {
          "duration": 0.080693,
          "end_time": "2022-03-24T06:01:57.776566",
          "exception": false,
          "start_time": "2022-03-24T06:01:57.695873",
          "status": "completed"
        },
        "tags": [],
        "id": "07bee216"
      },
      "outputs": [],
      "source": [
        "train_audio_dir = os.path.join(data_dir, 'train_audio')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "636e05b1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:58.018601Z",
          "iopub.status.busy": "2022-03-24T06:01:58.017713Z",
          "iopub.status.idle": "2022-03-24T06:01:58.019946Z",
          "shell.execute_reply": "2022-03-24T06:01:58.019293Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.636243Z"
        },
        "papermill": {
          "duration": 0.139752,
          "end_time": "2022-03-24T06:01:58.020096",
          "exception": false,
          "start_time": "2022-03-24T06:01:57.880344",
          "status": "completed"
        },
        "tags": [],
        "id": "636e05b1"
      },
      "outputs": [],
      "source": [
        "# for i in tqdm(range(len(train_df))):\n",
        "#     filename = train_df.loc[i,'filename']\n",
        "#     sig, sr = torchaudio.load(os.path.join(train_audio_dir, filename))\n",
        "#     train_df.loc[i, 'num_channels'] = sig.shape[0]  # number of audio channels (mono/stereo)\n",
        "#     train_df.loc[i, 'signal_len'] = sig.shape[1]  # signal length\n",
        "#     train_df.loc[i, 'sampling_rate'] = sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba65961",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:58.283075Z",
          "iopub.status.busy": "2022-03-24T06:01:58.282197Z",
          "iopub.status.idle": "2022-03-24T06:01:58.284416Z",
          "shell.execute_reply": "2022-03-24T06:01:58.283784Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.644564Z"
        },
        "papermill": {
          "duration": 0.135191,
          "end_time": "2022-03-24T06:01:58.284581",
          "exception": false,
          "start_time": "2022-03-24T06:01:58.149390",
          "status": "completed"
        },
        "tags": [],
        "id": "1ba65961"
      },
      "outputs": [],
      "source": [
        "# train_df['num_channels'] = train_df['num_channels'].astype('int64')\n",
        "# train_df['signal_len'] = train_df['signal_len'].astype('int64')\n",
        "# train_df['sampling_rate'] = train_df['sampling_rate'].astype('int64')\n",
        "# train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ca9f3e7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:58.552168Z",
          "iopub.status.busy": "2022-03-24T06:01:58.551302Z",
          "iopub.status.idle": "2022-03-24T06:01:58.553519Z",
          "shell.execute_reply": "2022-03-24T06:01:58.552872Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.652966Z"
        },
        "papermill": {
          "duration": 0.135922,
          "end_time": "2022-03-24T06:01:58.553665",
          "exception": false,
          "start_time": "2022-03-24T06:01:58.417743",
          "status": "completed"
        },
        "tags": [],
        "id": "8ca9f3e7"
      },
      "outputs": [],
      "source": [
        "# train_df.sampling_rate.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "229a6be9",
      "metadata": {
        "papermill": {
          "duration": 0.140106,
          "end_time": "2022-03-24T06:01:58.821395",
          "exception": false,
          "start_time": "2022-03-24T06:01:58.681289",
          "status": "completed"
        },
        "tags": [],
        "id": "229a6be9"
      },
      "source": [
        "we have unqiue sampling rate i.e., 32 KHz\n",
        "\n",
        "For a 1 second video, the array size will be 32000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "651b6f9e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:59.119243Z",
          "iopub.status.busy": "2022-03-24T06:01:59.118355Z",
          "iopub.status.idle": "2022-03-24T06:01:59.120697Z",
          "shell.execute_reply": "2022-03-24T06:01:59.120151Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.660923Z"
        },
        "papermill": {
          "duration": 0.129906,
          "end_time": "2022-03-24T06:01:59.120812",
          "exception": false,
          "start_time": "2022-03-24T06:01:58.990906",
          "status": "completed"
        },
        "tags": [],
        "id": "651b6f9e"
      },
      "outputs": [],
      "source": [
        "# sns.countplot(train_df.num_channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26b283b4",
      "metadata": {
        "papermill": {
          "duration": 0.079659,
          "end_time": "2022-03-24T06:01:59.275640",
          "exception": false,
          "start_time": "2022-03-24T06:01:59.195981",
          "status": "completed"
        },
        "tags": [],
        "id": "26b283b4"
      },
      "source": [
        "There are more number of two channel audios. So we will convert mono (1 channel ) audio to stereo (2 channel) audio by replication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ae6d64f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:59.438976Z",
          "iopub.status.busy": "2022-03-24T06:01:59.438154Z",
          "iopub.status.idle": "2022-03-24T06:01:59.439966Z",
          "shell.execute_reply": "2022-03-24T06:01:59.440364Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.668498Z"
        },
        "papermill": {
          "duration": 0.081678,
          "end_time": "2022-03-24T06:01:59.440521",
          "exception": false,
          "start_time": "2022-03-24T06:01:59.358843",
          "status": "completed"
        },
        "tags": [],
        "id": "8ae6d64f"
      },
      "outputs": [],
      "source": [
        "def MonoToStereo(aud, num_channel=2):\n",
        "    sig, sr = aud\n",
        "    if sig.shape[0] == num_channel:\n",
        "        return aud\n",
        "    else:\n",
        "        stereo_sig = torch.cat([sig, sig])\n",
        "    \n",
        "    return (stereo_sig, sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2c5d78",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:59.592187Z",
          "iopub.status.busy": "2022-03-24T06:01:59.591424Z",
          "iopub.status.idle": "2022-03-24T06:01:59.595223Z",
          "shell.execute_reply": "2022-03-24T06:01:59.594818Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.678474Z"
        },
        "papermill": {
          "duration": 0.080636,
          "end_time": "2022-03-24T06:01:59.595333",
          "exception": false,
          "start_time": "2022-03-24T06:01:59.514697",
          "status": "completed"
        },
        "tags": [],
        "id": "dd2c5d78"
      },
      "outputs": [],
      "source": [
        "# train_df.signal_len.min(), train_df.signal_len.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6686560e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:01:59.747875Z",
          "iopub.status.busy": "2022-03-24T06:01:59.747136Z",
          "iopub.status.idle": "2022-03-24T06:01:59.749200Z",
          "shell.execute_reply": "2022-03-24T06:01:59.749605Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.688302Z"
        },
        "papermill": {
          "duration": 0.080455,
          "end_time": "2022-03-24T06:01:59.749736",
          "exception": false,
          "start_time": "2022-03-24T06:01:59.669281",
          "status": "completed"
        },
        "tags": [],
        "id": "6686560e"
      },
      "outputs": [],
      "source": [
        "# f, ax = plt.subplots(figsize=(15,8))\n",
        "# sns.distplot(train_df.signal_len, ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d1979a1",
      "metadata": {
        "papermill": {
          "duration": 0.075989,
          "end_time": "2022-03-24T06:01:59.900852",
          "exception": false,
          "start_time": "2022-03-24T06:01:59.824863",
          "status": "completed"
        },
        "tags": [],
        "id": "7d1979a1"
      },
      "source": [
        "we need to have signal length to be of same size. So we will either pad the signal or truncate the signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9abf925",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:00.058293Z",
          "iopub.status.busy": "2022-03-24T06:02:00.057489Z",
          "iopub.status.idle": "2022-03-24T06:02:00.059577Z",
          "shell.execute_reply": "2022-03-24T06:02:00.059948Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.695663Z"
        },
        "papermill": {
          "duration": 0.084347,
          "end_time": "2022-03-24T06:02:00.060080",
          "exception": false,
          "start_time": "2022-03-24T06:01:59.975733",
          "status": "completed"
        },
        "tags": [],
        "id": "b9abf925"
      },
      "outputs": [],
      "source": [
        "# Let's consider the length of all videos to be 10 seconds (A hyperparam - to be tuned)\n",
        "max_len_ms = 10000 # 10k milliseconds ~ 10 seconds\n",
        "\n",
        "def pad_signal(aud, max_len_ms):\n",
        "    sig, sr = aud\n",
        "    num_channels, sig_len = sig.shape\n",
        "    max_len = sr // 1000 * max_len_ms\n",
        "    \n",
        "    if sig_len > max_len:\n",
        "        sig = sig[:, :max_len]\n",
        "    elif sig_len < max_len:\n",
        "        # padding both sides of the signal\n",
        "        pad_begin_len = random.randint(0, max_len - sig_len)\n",
        "        pad_end_len = max_len - sig_len - pad_begin_len\n",
        "        \n",
        "        # pad with zeros\n",
        "        pad_begin = torch.zeros((num_channels, pad_begin_len))\n",
        "        pad_end = torch.zeros((num_channels, pad_end_len))\n",
        "        \n",
        "        sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
        "    \n",
        "    return (sig, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation on raw audio\n",
        "下記リンクから実装内容を選択<br>\n",
        "https://github.com/iver56/audiomentations/tree/master/audiomentations/augmentations"
      ],
      "metadata": {
        "id": "OJrEorp0VBkJ"
      },
      "id": "OJrEorp0VBkJ"
    },
    {
      "cell_type": "code",
      "source": [
        "augment = Compose([\n",
        "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "    #TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "    #PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "    #Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5), \n",
        "])"
      ],
      "metadata": {
        "id": "x6SEGfBEVkgj"
      },
      "id": "x6SEGfBEVkgj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6403bcd7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:00.371526Z",
          "iopub.status.busy": "2022-03-24T06:02:00.370796Z",
          "iopub.status.idle": "2022-03-24T06:02:00.373281Z",
          "shell.execute_reply": "2022-03-24T06:02:00.372902Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.715550Z"
        },
        "papermill": {
          "duration": 0.082411,
          "end_time": "2022-03-24T06:02:00.373399",
          "exception": false,
          "start_time": "2022-03-24T06:02:00.290988",
          "status": "completed"
        },
        "tags": [],
        "id": "6403bcd7"
      },
      "outputs": [],
      "source": [
        "# Convert augmented audio to Mel Spectrogram\n",
        "def mel_spec(aud, n_mels=128, n_fft=None, hop_len=None):\n",
        "    sig, sr = aug_audio\n",
        "    top_db = 80\n",
        "    n_fft = n_fft or sr // 10\n",
        "    \n",
        "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
        "    # shape of spec: (channels, n_mels, time)\n",
        "    \n",
        "    # Convert to decibels\n",
        "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
        "    \n",
        "    # Add channel\n",
        "    spec = torch.cat([spec, spec.mean(dim=0, keepdim=True)])\n",
        "    return spec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
        "    mean = mean or X.mean()\n",
        "    std = std or X.std()\n",
        "    X = (X - mean) / (std + eps)\n",
        "    \n",
        "    _min, _max = X.min(), X.max()\n",
        "\n",
        "    if (_max - _min) > eps:\n",
        "        V = torch.clip(X, _min, _max)\n",
        "        V = 255 * (V - _min) / (_max - _min)\n",
        "        V = V.to(torch.uint8)\n",
        "    else:\n",
        "        V = torch.zeros_like(X, dtype=torch.uint8)\n",
        "\n",
        "    return V\n",
        "\n",
        "def normalize(image):\n",
        "        image = image.to(torch.float32) / 255.0\n",
        "        return image  \n"
      ],
      "metadata": {
        "id": "N55AKb4i0sLT"
      },
      "id": "N55AKb4i0sLT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47869c9c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:00.527852Z",
          "iopub.status.busy": "2022-03-24T06:02:00.527100Z",
          "iopub.status.idle": "2022-03-24T06:02:00.529290Z",
          "shell.execute_reply": "2022-03-24T06:02:00.529757Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.726290Z"
        },
        "papermill": {
          "duration": 0.082709,
          "end_time": "2022-03-24T06:02:00.529891",
          "exception": false,
          "start_time": "2022-03-24T06:02:00.447182",
          "status": "completed"
        },
        "tags": [],
        "id": "47869c9c"
      },
      "outputs": [],
      "source": [
        "# Data augmentation on mel spectrogram: Time and Frequency Masking\n",
        "def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
        "    _, n_mels, n_steps = spec.shape\n",
        "    mask_value = spec.mean()\n",
        "    aug_spec = spec\n",
        "    \n",
        "    freq_mask_param = max_mask_pct * n_mels\n",
        "    for _ in range(n_freq_masks):\n",
        "        aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
        "        \n",
        "    time_mask_param = max_mask_pct * n_steps\n",
        "    for _ in range(n_time_masks):\n",
        "        aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
        "        \n",
        "    return aug_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51f6fec3",
      "metadata": {
        "papermill": {
          "duration": 0.074623,
          "end_time": "2022-03-24T06:02:00.679007",
          "exception": false,
          "start_time": "2022-03-24T06:02:00.604384",
          "status": "completed"
        },
        "tags": [],
        "id": "51f6fec3"
      },
      "source": [
        "Preprocessing on one signal sample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = random.randint(0, len(train_df))\n",
        "filename = train_df.loc[idx,'filename']\n",
        "sig, sr = torchaudio.load(os.path.join(train_audio_dir, filename))\n",
        "audio_sample = (sig, sr)\n",
        "\n",
        "# mono to stereo (if mono)\n",
        "audio = MonoToStereo(audio_sample)\n",
        "\n",
        "# Pad or Truncate\n",
        "audio = pad_signal(audio, max_len_ms)\n",
        "\n",
        "# Augment on raw audio\n",
        "# aug_audio = augment(*audio)\n",
        "# aug_audio = (aug_audio, sr)\n",
        "aug_audio = audio\n",
        "\n",
        "# Convert to Mel Spectrogram\n",
        "spec = mono_to_color(mel_spec(aug_audio))\n",
        "\n",
        "# Normarize\n",
        "spec = normalize(spec)\n",
        "\n",
        "# Augment on mel spec\n",
        "aug_spec =  spec #spectro_augment(spec)\n",
        "aug_spec.shape"
      ],
      "metadata": {
        "id": "ugMWHzhjqXLc"
      },
      "id": "ugMWHzhjqXLc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16784678",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:01.205174Z",
          "iopub.status.busy": "2022-03-24T06:02:01.204348Z",
          "iopub.status.idle": "2022-03-24T06:02:02.057275Z",
          "shell.execute_reply": "2022-03-24T06:02:02.060883Z",
          "shell.execute_reply.started": "2022-03-24T05:58:36.865273Z"
        },
        "papermill": {
          "duration": 0.942379,
          "end_time": "2022-03-24T06:02:02.061253",
          "exception": false,
          "start_time": "2022-03-24T06:02:01.118874",
          "status": "completed"
        },
        "tags": [],
        "id": "16784678"
      },
      "outputs": [],
      "source": [
        "aug_spec_np = aug_spec.permute(1,2,0).numpy()\n",
        "f, ax = plt.subplots(figsize=(15,8))\n",
        "plt.imshow(aug_spec_np[:, :, 0])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "f, ax = plt.subplots(figsize=(15,8))\n",
        "plt.imshow(aug_spec_np[:, :, 1])\n",
        "plt.show()\n",
        "f, ax = plt.subplots(figsize=(15,8))\n",
        "plt.imshow(aug_spec_np[:, :, 1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio, display\n",
        "def play_audio(waveform, sample_rate):\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  if num_channels == 1:\n",
        "    display(Audio(waveform[0], rate=sample_rate))\n",
        "  elif num_channels == 2:\n",
        "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
        "  else:\n",
        "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")"
      ],
      "metadata": {
        "id": "czbt5czSWO42"
      },
      "id": "czbt5czSWO42",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "play_audio(sig, sr)"
      ],
      "metadata": {
        "id": "suR7AWUsWZP2"
      },
      "id": "suR7AWUsWZP2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f8e8d360",
      "metadata": {
        "papermill": {
          "duration": 0.143029,
          "end_time": "2022-03-24T06:02:02.385639",
          "exception": false,
          "start_time": "2022-03-24T06:02:02.242610",
          "status": "completed"
        },
        "tags": [],
        "id": "f8e8d360"
      },
      "source": [
        "# Building Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0ccdf35",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:02.642778Z",
          "iopub.status.busy": "2022-03-24T06:02:02.642032Z",
          "iopub.status.idle": "2022-03-24T06:02:02.644869Z",
          "shell.execute_reply": "2022-03-24T06:02:02.644372Z",
          "shell.execute_reply.started": "2022-03-24T05:58:37.806282Z"
        },
        "papermill": {
          "duration": 0.099447,
          "end_time": "2022-03-24T06:02:02.644981",
          "exception": false,
          "start_time": "2022-03-24T06:02:02.545534",
          "status": "completed"
        },
        "tags": [],
        "id": "b0ccdf35"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, audio_dir, df, labels, max_len_ms=10000, shift_limit=0.4, input_size=224):\n",
        "        self.train_audio_dir = audio_dir\n",
        "        self.train_df = df\n",
        "        self.max_len_ms = max_len_ms\n",
        "        self.shift_limit = shift_limit\n",
        "        self.input_size = input_size\n",
        "        self.num_classes = len(labels)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.train_df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.train_df.loc[index, 'filename']\n",
        "        labels = [self.train_df.loc[index, 'primary_label']]\n",
        "        labels.extend(eval(self.train_df.loc[index, 'secondary_labels']))\n",
        "        labels = list(set(labels))\n",
        "        \n",
        "        sig, sr = torchaudio.load(os.path.join(self.train_audio_dir, filename))\n",
        "        audio = (sig, sr)\n",
        "        \n",
        "        ##################        \n",
        "        # process signal #\n",
        "        ##################\n",
        "        \n",
        "        # mono to stereo (if mono)\n",
        "        audio = MonoToStereo(audio)\n",
        "\n",
        "        # Pad or Truncate\n",
        "        audio = pad_signal(audio, self.max_len_ms)\n",
        "\n",
        "        # Augment raw audio\n",
        "        # aug_audio = augment(*audio)\n",
        "        # aug_audio = (aug_audio, sr)\n",
        "        aug_audio = audio\n",
        "\n",
        "        # Convert to Mel Spectrogram\n",
        "        spec = mono_to_color(mel_spec(aug_audio))\n",
        "\n",
        "        # Normarize\n",
        "        spec = normalize(spec)\n",
        "\n",
        "        # Augment mel spec\n",
        "        # aug_spec = spectro_augment(spec)\n",
        "        aug_spec=spec\n",
        "\n",
        "        # make multilabel data\n",
        "        y = torch.tensor([label2id[label] for label in labels])\n",
        "        y_onehot = nn.functional.one_hot(y, num_classes=self.num_classes).sum(dim=0).float()\n",
        "\n",
        "        # batch weight\n",
        "        # 現状、精度に寄与しないのでコメントアウト\n",
        "        # weights = torch.clone(y_onehot)\n",
        "        # weights.apply_(lambda x:100 if x==1 else 1)\n",
        "        \n",
        "        return aug_spec, y_onehot #, weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db153bb9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:02.820042Z",
          "iopub.status.busy": "2022-03-24T06:02:02.819251Z",
          "iopub.status.idle": "2022-03-24T06:02:02.822028Z",
          "shell.execute_reply": "2022-03-24T06:02:02.821607Z",
          "shell.execute_reply.started": "2022-03-24T05:58:37.818065Z"
        },
        "papermill": {
          "duration": 0.092823,
          "end_time": "2022-03-24T06:02:02.822137",
          "exception": false,
          "start_time": "2022-03-24T06:02:02.729314",
          "status": "completed"
        },
        "tags": [],
        "id": "db153bb9"
      },
      "outputs": [],
      "source": [
        "max_len_ms = 10000\n",
        "shift_limit = 0.4\n",
        "input_size = 224\n",
        "dataset = CustomDataset(train_audio_dir, train_df, labels, max_len_ms, shift_limit, input_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42675abb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:02.996729Z",
          "iopub.status.busy": "2022-03-24T06:02:02.995955Z",
          "iopub.status.idle": "2022-03-24T06:02:03.000282Z",
          "shell.execute_reply": "2022-03-24T06:02:02.999871Z",
          "shell.execute_reply.started": "2022-03-24T05:58:37.826301Z"
        },
        "papermill": {
          "duration": 0.093883,
          "end_time": "2022-03-24T06:02:03.000392",
          "exception": false,
          "start_time": "2022-03-24T06:02:02.906509",
          "status": "completed"
        },
        "tags": [],
        "id": "42675abb"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 不均衡データの問題解消のため、samplerを利用してoversamplingを行う"
      ],
      "metadata": {
        "id": "Rv7ikrl_YiP6"
      },
      "id": "Rv7ikrl_YiP6"
    },
    {
      "cell_type": "code",
      "source": [
        "1./label_weights.loc['brnowl']"
      ],
      "metadata": {
        "id": "feU2WcGzLSLX"
      },
      "id": "feU2WcGzLSLX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_weights = train_df.copy()\n",
        "train_df_weights['weight'] = [label_weights[label] for label in train_df['primary_label']]\n",
        "train_df_weights[train_df_weights['primary_label']=='brnowl']"
      ],
      "metadata": {
        "id": "wiWvVYDYQHZA"
      },
      "id": "wiWvVYDYQHZA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_weight = train_df_weights['weight'].values\n",
        "sampler = torch.utils.data.WeightedRandomSampler(samples_weight, 5000)"
      ],
      "metadata": {
        "id": "lp5d_GhxStuz"
      },
      "id": "lp5d_GhxStuz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "samplerの利用によるクラス比の違い"
      ],
      "metadata": {
        "id": "Jh6WZoOVZf-5"
      },
      "id": "Jh6WZoOVZf-5"
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots(figsize=(30,8))\n",
        "sns.countplot(x=\"primary_label\", data=train_df, ax=ax)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
        "plt.show()\n",
        "\n",
        "sampler_test = list(sampler)\n",
        "f, ax = plt.subplots(figsize=(30,8))\n",
        "sns.countplot(x=\"primary_label\", data=train_df.loc[sampler_test,:].sort_values('primary_label'), ax=ax)\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)\n",
        "plt.show()\n",
        "# train_df.loc[sampler_test,'primary_label'].groupby('primary_label')"
      ],
      "metadata": {
        "id": "_E-Kj9vEL7Zu"
      },
      "id": "_E-Kj9vEL7Zu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf2cc4f1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:03.174899Z",
          "iopub.status.busy": "2022-03-24T06:02:03.174097Z",
          "iopub.status.idle": "2022-03-24T06:02:03.176598Z",
          "shell.execute_reply": "2022-03-24T06:02:03.176119Z",
          "shell.execute_reply.started": "2022-03-24T05:58:37.838447Z"
        },
        "papermill": {
          "duration": 0.091229,
          "end_time": "2022-03-24T06:02:03.176709",
          "exception": false,
          "start_time": "2022-03-24T06:02:03.085480",
          "status": "completed"
        },
        "tags": [],
        "id": "bf2cc4f1"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "# DataLoaderのnum_workersは、前処理部分の並列実行を可能にしてくれる\n",
        "# https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
        "# train_loader = DataLoader(train_dataset, sampler=ImbalancedDatasetSampler(train_dataset), batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "train_loader = DataLoader(dataset, sampler=sampler, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2c0c3c",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:03.352630Z",
          "iopub.status.busy": "2022-03-24T06:02:03.352056Z",
          "iopub.status.idle": "2022-03-24T06:02:06.074003Z",
          "shell.execute_reply": "2022-03-24T06:02:06.073511Z",
          "shell.execute_reply.started": "2022-03-24T05:58:37.845177Z"
        },
        "papermill": {
          "duration": 2.81263,
          "end_time": "2022-03-24T06:02:06.074139",
          "exception": false,
          "start_time": "2022-03-24T06:02:03.261509",
          "status": "completed"
        },
        "tags": [],
        "id": "4d2c0c3c"
      },
      "outputs": [],
      "source": [
        "inputs, targets = next(iter(train_loader))\n",
        "print(inputs.shape, targets.shape)\n",
        "# print(targets[0], weights[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "708267d2",
      "metadata": {
        "papermill": {
          "duration": 0.092347,
          "end_time": "2022-03-24T06:02:06.264720",
          "exception": false,
          "start_time": "2022-03-24T06:02:06.172373",
          "status": "completed"
        },
        "tags": [],
        "id": "708267d2"
      },
      "source": [
        "Cool!!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f750765",
      "metadata": {
        "papermill": {
          "duration": 0.087478,
          "end_time": "2022-03-24T06:02:06.445352",
          "exception": false,
          "start_time": "2022-03-24T06:02:06.357874",
          "status": "completed"
        },
        "tags": [],
        "id": "6f750765"
      },
      "source": [
        "Let's build model architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82b629d6",
      "metadata": {
        "papermill": {
          "duration": 0.085926,
          "end_time": "2022-03-24T06:02:06.618342",
          "exception": false,
          "start_time": "2022-03-24T06:02:06.532416",
          "status": "completed"
        },
        "tags": [],
        "id": "82b629d6"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model作成の関数\n",
        "基本的に、モデルを変更する場合はここの修正を行う！"
      ],
      "metadata": {
        "id": "hB3O4Exfe3UN"
      },
      "id": "hB3O4Exfe3UN"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(labels, device):\n",
        "  model = torchvision.models.resnet50()\n",
        "  model.fc = torch.nn.Sequential(\n",
        "    torch.nn.Linear(\n",
        "        in_features=model.fc.in_features,\n",
        "        out_features=len(labels)\n",
        "    ),\n",
        "    torch.nn.Sigmoid()\n",
        "  )\n",
        "  return model.to(device)"
      ],
      "metadata": {
        "id": "AVfnkoVYeRyW"
      },
      "id": "AVfnkoVYeRyW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### modelのチェック"
      ],
      "metadata": {
        "id": "b0Bmj01WfAOH"
      },
      "id": "b0Bmj01WfAOH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83e8d690",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:06.796781Z",
          "iopub.status.busy": "2022-03-24T06:02:06.796209Z",
          "iopub.status.idle": "2022-03-24T06:02:07.170111Z",
          "shell.execute_reply": "2022-03-24T06:02:07.169689Z",
          "shell.execute_reply.started": "2022-03-24T05:58:40.465915Z"
        },
        "papermill": {
          "duration": 0.465379,
          "end_time": "2022-03-24T06:02:07.170232",
          "exception": false,
          "start_time": "2022-03-24T06:02:06.704853",
          "status": "completed"
        },
        "tags": [],
        "id": "83e8d690"
      },
      "outputs": [],
      "source": [
        "model = create_model(labels, 'cpu')\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d0d8bf",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:07.537892Z",
          "iopub.status.busy": "2022-03-24T06:02:07.537337Z",
          "iopub.status.idle": "2022-03-24T06:02:14.241231Z",
          "shell.execute_reply": "2022-03-24T06:02:14.241677Z",
          "shell.execute_reply.started": "2022-03-24T05:58:40.842707Z"
        },
        "papermill": {
          "duration": 6.798692,
          "end_time": "2022-03-24T06:02:14.241841",
          "exception": false,
          "start_time": "2022-03-24T06:02:07.443149",
          "status": "completed"
        },
        "tags": [],
        "id": "70d0d8bf"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "output = model(inputs)\n",
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a143705",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:14.423575Z",
          "iopub.status.busy": "2022-03-24T06:02:14.422709Z",
          "iopub.status.idle": "2022-03-24T06:02:14.424769Z",
          "shell.execute_reply": "2022-03-24T06:02:14.425130Z",
          "shell.execute_reply.started": "2022-03-24T05:58:47.209897Z"
        },
        "papermill": {
          "duration": 0.095948,
          "end_time": "2022-03-24T06:02:14.425266",
          "exception": false,
          "start_time": "2022-03-24T06:02:14.329318",
          "status": "completed"
        },
        "tags": [],
        "id": "4a143705"
      },
      "outputs": [],
      "source": [
        "LERANING_RATE = 1e-2\n",
        "\n",
        "# Defining loss and optimizer\n",
        "criterion = nn.BCELoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=LERANING_RATE)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LERANING_RATE, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16774d06",
      "metadata": {
        "papermill": {
          "duration": 0.086552,
          "end_time": "2022-03-24T06:02:14.598561",
          "exception": false,
          "start_time": "2022-03-24T06:02:14.512009",
          "status": "completed"
        },
        "tags": [],
        "id": "16774d06"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_confusion_matrix(y_true, y_pred):\n",
        "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  class_id  = np.unique(np.concatenate([y_true,y_pred]))\n",
        "  df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix)*10, index = class_id, columns=class_id)\n",
        "  plt.figure(figsize=(12,7))\n",
        "  return sns.heatmap(df_cm).get_figure()"
      ],
      "metadata": {
        "id": "0XGTWZ_hNW4i"
      },
      "id": "0XGTWZ_hNW4i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_roc_curve(y_true, y_pred):\n",
        "#   fprs, tprs = [], []\n",
        "#   for i in range(y_true.shape[1]):\n",
        "#     fpr, tpr, _ = roc_curve(y_true[:,i], y_pred[:,i])"
      ],
      "metadata": {
        "id": "kvQBAJo3ThpR"
      },
      "id": "kvQBAJo3ThpR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = train_df.loc[val_dataset.indices,['primary_label','secondary_labels']]\n",
        "val_df['secondary_labels'] = val_df['secondary_labels'].apply(lambda x:eval(x))\n",
        "pri = val_df['primary_label'].values\n",
        "for sec in val_df['secondary_labels']:\n",
        "  pri = np.append(pri, sec)\n",
        "len(np.unique(pri))\n"
      ],
      "metadata": {
        "id": "GoWuKdINunIo"
      },
      "id": "GoWuKdINunIo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52ebb561",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:14.781865Z",
          "iopub.status.busy": "2022-03-24T06:02:14.781014Z",
          "iopub.status.idle": "2022-03-24T06:02:14.783469Z",
          "shell.execute_reply": "2022-03-24T06:02:14.783046Z",
          "shell.execute_reply.started": "2022-03-24T05:58:47.217971Z"
        },
        "papermill": {
          "duration": 0.097539,
          "end_time": "2022-03-24T06:02:14.783594",
          "exception": false,
          "start_time": "2022-03-24T06:02:14.686055",
          "status": "completed"
        },
        "tags": [],
        "id": "52ebb561"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, data_loader, device, criterion, optimizer, num_epoch, writer):\n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = None\n",
        "    y_true = None\n",
        "    auc = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(tqdm(data_loader), num_epoch*len(data_loader)):\n",
        "        x = x.to(device) \n",
        "        y = y.to(device) \n",
        "        # weights = weights.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "\n",
        "        loss = criterion(output, y) #nn.functional.binary_cross_entropy(output, y, weights) \n",
        "\n",
        "        writer.add_scalar('Loss/train_iter', loss.item(), batch_idx)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # _, preds = torch.max(output, dim=1)\n",
        "        # preds = preds.cpu()\n",
        "        output = output.detach().cpu()\n",
        "        y = y.cpu()\n",
        "        y_pred = np.concatenate([y_pred, output.numpy()]) if y_pred is not None else output.numpy()\n",
        "        y_true = np.concatenate([y_true, y.numpy()]) if y_true is not None else y.numpy()\n",
        "        # auc += roc_auc_score(y.numpy(), output.detach().cpu().numpy())\n",
        "        # total += y.size(0)\n",
        "\n",
        "    # writer.add_figure(\"confusion matrix/train\", create_confusion_matrix(y_true, y_pred),num_epoch)\n",
        "    # print(f'y_pred:{y_pred}, y_true:{y_true}')\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    return auc, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757ec060",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:14.967257Z",
          "iopub.status.busy": "2022-03-24T06:02:14.966465Z",
          "iopub.status.idle": "2022-03-24T06:02:14.968539Z",
          "shell.execute_reply": "2022-03-24T06:02:14.968906Z",
          "shell.execute_reply.started": "2022-03-24T05:58:47.228593Z"
        },
        "papermill": {
          "duration": 0.097632,
          "end_time": "2022-03-24T06:02:14.969044",
          "exception": false,
          "start_time": "2022-03-24T06:02:14.871412",
          "status": "completed"
        },
        "tags": [],
        "id": "757ec060"
      },
      "outputs": [],
      "source": [
        "def val_epoch(model, data_loader, device, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = None\n",
        "    y_true = None\n",
        "    auc = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x, y) in enumerate(tqdm(data_loader)):\n",
        "            x = x.to(device) \n",
        "            y = y.to(device) \n",
        "\n",
        "            output = model(x)\n",
        "\n",
        "            loss = criterion(output, y)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # _, preds = torch.max(output, dim=1)\n",
        "            # preds = preds.cpu()\n",
        "            output = output.detach().cpu()\n",
        "            y = y.cpu()\n",
        "            y_pred = np.concatenate([y_pred, output.numpy()]) if y_pred is not None else output.numpy()\n",
        "            y_true = np.concatenate([y_true, y.numpy()]) if y_true is not None else y.numpy()\n",
        "            # auc += roc_auc_score(y.numpy(), output.detach().cpu().numpy())\n",
        "            # total += y.size(0)\n",
        "\n",
        "    # writer.add_figure(\"confusion matrix/train\", create_confusion_matrix(y_true, y_pred),num_epoch)\n",
        "    auc = roc_auc_score(y_true, y_pred)\n",
        "\n",
        "    return auc, np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b572fcd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:15.153536Z",
          "iopub.status.busy": "2022-03-24T06:02:15.152671Z",
          "iopub.status.idle": "2022-03-24T06:02:15.154562Z",
          "shell.execute_reply": "2022-03-24T06:02:15.154962Z",
          "shell.execute_reply.started": "2022-03-24T05:58:47.238775Z"
        },
        "papermill": {
          "duration": 0.097599,
          "end_time": "2022-03-24T06:02:15.155092",
          "exception": false,
          "start_time": "2022-03-24T06:02:15.057493",
          "status": "completed"
        },
        "tags": [],
        "id": "2b572fcd"
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, device, train_loader, val_loader, criterion, optimizer, model_name, log_dir=None, comment=''):\n",
        "    # logの配置ディレクトリを変えたい場合はlog_dirを引数として渡す\n",
        "    # log自体に名前を付けて差別化したいときは、commentに適当な文字列を引数として渡す\n",
        "    writer = SummaryWriter(log_dir=log_dir, comment=comment)\n",
        "\n",
        "    best_val_auc = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Epoch: {epoch + 1}/{epochs}')\n",
        "        print('-' * 10)\n",
        "        print('Training')\n",
        "        train_auc, train_loss = train_epoch(model, train_loader, device, criterion, optimizer, epoch, writer)\n",
        "        # AUCの計算上、クラス数が0 or 1のみのデータがあるとエラーが出るので、一旦valはなし\n",
        "        # print('\\nValidating')\n",
        "        # val_auc, val_loss = val_epoch(model, val_loader, device, criterion)\n",
        "\n",
        "        print(f'\\nTrain Loss: {train_loss}\\tTrain AUC: {train_auc}')\n",
        "        # print(f'Val Loss: {val_loss}\\tVal AUC: {val_auc}')\n",
        "\n",
        "        writer.add_scalar('Loss/train',train_loss, epoch)\n",
        "        writer.add_scalar('AUC/train',train_auc, epoch)\n",
        "        # writer.add_scalar('Loss/val',val_loss, epoch)\n",
        "        # writer.add_scalar('AUC/val',val_auc, epoch)\n",
        "        # writer.add_figure('confusion matrix/val', cf_matrix, epoch)\n",
        "\n",
        "        if train_auc > best_val_auc:\n",
        "            best_val_acc = train_auc\n",
        "            torch.save(model.state_dict(), model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a759a1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:15.370542Z",
          "iopub.status.busy": "2022-03-24T06:02:15.369913Z",
          "iopub.status.idle": "2022-03-24T06:02:15.374304Z",
          "shell.execute_reply": "2022-03-24T06:02:15.373758Z",
          "shell.execute_reply.started": "2022-03-24T05:58:47.249965Z"
        },
        "papermill": {
          "duration": 0.131926,
          "end_time": "2022-03-24T06:02:15.374437",
          "exception": false,
          "start_time": "2022-03-24T06:02:15.242511",
          "status": "completed"
        },
        "tags": [],
        "id": "c9a759a1"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modelの上書きを防ぐため、指定した名前or日付をつける\n",
        "suffix = None # 日付以外の名前を付けたい場合はここを適当な文字列に変更\n",
        "suffix = suffix or datetime.now().strftime(\"%Y%m%d%H%M\")\n",
        "model_name = os.path.join(model_dir, f\"best_model_{suffix}.pth.tar\")"
      ],
      "metadata": {
        "id": "d9NfpxqVY7e1"
      },
      "id": "d9NfpxqVY7e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = os.path.join(root_dir, 'runs')\n",
        "%tensorboard --logdir=$log_dir"
      ],
      "metadata": {
        "id": "v5jNLg4UveNd"
      },
      "id": "v5jNLg4UveNd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dbc5793",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T06:02:15.558815Z",
          "iopub.status.busy": "2022-03-24T06:02:15.558025Z",
          "iopub.status.idle": "2022-03-24T08:53:08.342970Z",
          "shell.execute_reply": "2022-03-24T08:53:08.343345Z"
        },
        "papermill": {
          "duration": 10252.881092,
          "end_time": "2022-03-24T08:53:08.343548",
          "exception": false,
          "start_time": "2022-03-24T06:02:15.462456",
          "status": "completed"
        },
        "tags": [],
        "id": "8dbc5793"
      },
      "outputs": [],
      "source": [
        "model = model.to(DEVICE)\n",
        "train(model, EPOCHS, DEVICE, train_loader, val_loader, criterion, optimizer, model_name, log_dir=log_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3db2a93e",
      "metadata": {
        "papermill": {
          "duration": 1.333719,
          "end_time": "2022-03-24T08:53:11.072791",
          "exception": false,
          "start_time": "2022-03-24T08:53:09.739072",
          "status": "completed"
        },
        "tags": [],
        "id": "3db2a93e"
      },
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61a8d9f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T08:53:13.719497Z",
          "iopub.status.busy": "2022-03-24T08:53:13.718607Z",
          "iopub.status.idle": "2022-03-24T08:53:13.810553Z",
          "shell.execute_reply": "2022-03-24T08:53:13.810996Z"
        },
        "papermill": {
          "duration": 1.425864,
          "end_time": "2022-03-24T08:53:13.811251",
          "exception": false,
          "start_time": "2022-03-24T08:53:12.385387",
          "status": "completed"
        },
        "tags": [],
        "id": "c61a8d9f"
      },
      "outputs": [],
      "source": [
        "# 特定のモデルの出力を見たい場合は、ここでモデルのパスを指定する\n",
        "# model_name = '/content/drive/MyDrive/colab/BirdCLEF/models/best_model_202204140824.pth.tar'\n",
        "model.load_state_dict(torch.load(model_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(inputs.to(DEVICE))\n",
        "output[1], targets[1]"
      ],
      "metadata": {
        "id": "hXCsStN-cg-J"
      },
      "id": "hXCsStN-cg-J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets[1].argmax()"
      ],
      "metadata": {
        "id": "H_hRihEPyOlP"
      },
      "id": "H_hRihEPyOlP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output[1,102], targets[1,102]"
      ],
      "metadata": {
        "id": "_IJ3MmwRdXkv"
      },
      "id": "_IJ3MmwRdXkv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels[92]"
      ],
      "metadata": {
        "id": "nPIbaSmkfHtU"
      },
      "id": "nPIbaSmkfHtU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 10321.967406,
      "end_time": "2022-03-24T08:53:42.503490",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-03-24T06:01:40.536084",
      "version": "2.3.3"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}